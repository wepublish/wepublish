name: Synchronize production with staging database

#on:
#  workflow_dispatch:
#   inputs:
#      project:
#        description: 'Name of the project you want to sync the database for'
#        required: true
#        type: string

on:
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  sync-db:
    name: Sync staging with production database
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'

    steps:
      - uses: actions/checkout@v3

      - name: Set up Helm
        uses: azure/setup-helm@v1
        with:
          version: '3.12.3'

      - name: Authenticate kubectl
        uses: 'google-github-actions/auth@v1'
        with:
          project_id: ${{ secrets.GCLOUD_PROJECT_ID }}
          workload_identity_provider: ${{ secrets.GCLOUD_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: ${{ secrets.GCLOUD_SERVICE_ACCOUNT }}

      - name: Prepare kubectl
        uses: 'google-github-actions/get-gke-credentials@v1'
        with:
          project_id: ${{ secrets.GCLOUD_PROJECT_ID }}
          cluster_name: development
          location: europe-west6

      - name: Port forward PostgreSQL
        run: |
          kubectl port-forward -n staging svc/wnti-database-postgres 5432:5432 &

      - name: Install PostgreSQL Client
        run: |
          sudo sh -c 'echo "deb http://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'
          wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add -
          sudo apt-get update
          sudo apt-get install -y postgresql-client-17 curl gzip jq

      - name: Get and unpack project production database
        run: |
          curl --output database.dump.gz https://${{ secrets.HTTP_PROD_DUMP_SHARE_USER }}:${{ secrets.HTTP_PROD_DUMP_SHARE_PASSWORD }}@${{ secrets.HTTP_PROD_DUMP_SHARE_URL }}/wnti.sql.gz
          gzip -d database.dump.gz

      - name: Restore Dump to Review Database
        env:
          PGPASSWORD: foo
        run: |
          psql -h 127.0.0.1 -U postgres -d wepublish -f database.dump

      - name: Rerun database migrations
        run: |
          JOB_NAME=$(kubectl -n staging get jobs --sort-by='{.metadata.creationTimestamp}' |grep "wnti-app-wepublish-migration" |tail -n 1 | awk '{print $1}')
          kubectl -n staging get job "$JOB_NAME" -o json | jq --arg name "${JOB_NAME}r" '
            .metadata.name = $name
            | del(
            .metadata.uid,
            .metadata.resourceVersion,
            .metadata.creationTimestamp,
            .metadata.managedFields,
            .status
            )
            | del(.spec.selector, .spec.manualSelector)
            | (.spec.template.metadata.labels // {}) as $l
            | .spec.template.metadata.labels = ($l
            | del(
            .["job-name"],
            .["batch.kubernetes.io/job-name"],
            .["controller-uid"],
            .["batch.kubernetes.io/controller-uid"],
            .["pod-template-hash"]
            )
            )
            ' | kubectl -n staging apply -f -          

      - name: Cleanup
        run: rm database.dump